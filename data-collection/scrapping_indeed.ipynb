{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8hIIY7Nehw3N"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import requests as rq\n",
        "from bs4 import BeautifulSoup as bs\n",
        "from time import sleep\n",
        "from time import time\n",
        "from random import randint\n",
        "from warnings import warn\n",
        "import json\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most websites do not leave job postings for more than 2-5 months hence getting job posting of previous years from the jobsites directly is impossible. \n",
        "\n",
        "To get old job postings, I'm extracting data from a web archive called [the wayback machine](https://archive.org/web/). The drawback to this is that the links are not clickable hence being able to extract the job posting descriptions might be difficult."
      ],
      "metadata": {
        "id": "J0z1P6WcliHx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scraping Indeed job site "
      ],
      "metadata": {
        "id": "q1fHZ7zVrK8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "roles = [\n",
        "    'Marketing Technologist',\n",
        "    'SEO Consultant',\n",
        "    'Web analytics Developer',\n",
        "    'Digital Marketing Manager',\n",
        "    'Social media manager',\n",
        "    'Content Manager',\n",
        "    'Information Architect',\n",
        "    'UX designer',\n",
        "    'UI Designer',\n",
        "    'Front end designer',\n",
        "    'Front end developer',\n",
        "    'Mobile Developer',\n",
        "    'Full stack developer',\n",
        "    'Software Developer',\n",
        "    'WordPress Developer',\n",
        "    'Python Developer',\n",
        "    'Systems Engineer',\n",
        "    'Data Architect',\n",
        "    'Database Administrator',\n",
        "    'Data Analyst', \n",
        "    'Data scientist',\n",
        "    'Cloud Architect',\n",
        "    'DevOps Manager',\n",
        "    'Agile project manager',\n",
        "    'Product Manager',\n",
        "    'Security specialist',\n",
        "    'QA (Quality Assurance) specialist',\n",
        "    'Game developer',\n",
        "    'Computer Graphics animator',\n",
        "    'Information security analyst',\n",
        "    'Network and system administrator',\n",
        "    'Product owner'\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "qJhojZyvrRL-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_availability(link):\n",
        "  url = f'http://archive.org/wayback/available?url={link}'\n",
        "  urls = rq.get(url).text\n",
        "  parse_url = json.loads(urls)  \n",
        "  return parse_url"
      ],
      "metadata": {
        "id": "X7LqF8SsZ6Nm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_availability('www.indeed.com/jobs?q=data+scientist')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRBOdkEcbM3x",
        "outputId": "0a214fd3-39f6-444b-e325-c3771611b021"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'url': 'www.indeed.com/jobs?q=data scientist',\n",
              " 'archived_snapshots': {'closest': {'status': '200',\n",
              "   'available': True,\n",
              "   'url': 'http://web.archive.org/web/20201112020605/https://www.indeed.com/jobs?q=data%20scientist',\n",
              "   'timestamp': '20201112020605'}}}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = f'http://web.archive.org/cdx/search/cdx?url=www.indeed.com/jobs?q=data+scientist&amp;explvl=entry_level&from=20130101&to=20230215&output=json'\n",
        "urls = rq.get(url).text\n",
        "parse_url = json.loads(urls)"
      ],
      "metadata": {
        "id": "WrTifm1QYeWI"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_archive_link(link):\n",
        "  url = f'http://web.archive.org/cdx/search/cdx?url={link}&from=20130101&to=20230215&output=json'\n",
        "  urls = rq.get(url).text\n",
        "  parse_url = json.loads(urls) #parses the JSON from urls.\n",
        "  # print(parse_url)\n",
        "  url_list = []\n",
        "  for i in range(1,len(parse_url)):\n",
        "    orig_url = parse_url[i][2]\n",
        "    tstamp = parse_url[i][1]\n",
        "    waylink = tstamp+'/'+orig_url\n",
        "    url_list.append(waylink)\n",
        "  # print(url_list)\n",
        "\n",
        "  ## Compiles final url pattern.\n",
        "  final_list = []\n",
        "  for url in url_list:\n",
        "    final_url = 'https://web.archive.org/web/'+url\n",
        "    final_list.append(final_url)\n",
        "    # print(final_list)\n",
        "\n",
        "  return final_list"
      ],
      "metadata": {
        "id": "K1CK7NbvIlzP"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract company\n",
        "def extract_company(div): \n",
        "    company = div.find_all(name=\"span\", attrs={\"class\":\"company\"})\n",
        "    if len(company) > 0:\n",
        "      for b in company:\n",
        "        return (b.text.strip())\n",
        "    else:\n",
        "      sec_try = div.find_all(name=\"span\", attrs={\"class\":\"result-link-source\"})\n",
        "      for span in sec_try:\n",
        "          return (span.text.strip())\n",
        "    return 'NOT_FOUND'\n",
        "\n",
        "\n",
        "# extract job salary\n",
        "def extract_salary(div): \n",
        "    salaries = []\n",
        "    try:\n",
        "      return (div.find('nobr').text)\n",
        "    except:\n",
        "      try:\n",
        "        div_two = div.find(name='div', attrs={'class':'salary no-wrap'})\n",
        "        div_three = div_two.find('div')\n",
        "        salaries.append(div_three.text.strip())\n",
        "        return salaries\n",
        "      except:\n",
        "        try:\n",
        "          div_two = div.find(name='div', attrs={'class':'sjcl'})\n",
        "          div_three = div_two.find('div')\n",
        "          salaries.append(div_three.text.strip())\n",
        "          return salaries\n",
        "        except:\n",
        "          return ('NOT_FOUND')\n",
        "    return 'NOT_FOUND'\n",
        "\n",
        "\n",
        "# extract job location\n",
        "def extract_location(div):\n",
        "  for span in div.findAll('span', attrs={'class': 'location'}):\n",
        "    return (span.text)\n",
        "  return 'NOT_FOUND'\n",
        "\n",
        "\n",
        "# extract job title\n",
        "def extract_job_title(div):\n",
        "  for a in div.find_all(name='a', attrs={'data-tn-element':'jobTitle'}):\n",
        "    return (a['title'])\n",
        "  return('NOT_FOUND')\n",
        "\n",
        "\n",
        "# extract jd summary\n",
        "def extract_summary(div): \n",
        "  spans = div.findAll('span', attrs={'class': 'summary'})\n",
        "  for span in spans:\n",
        "    return (span.text.strip())\n",
        "  return 'NOT_FOUND'\n",
        " \n",
        "\n",
        "# extract link of job description \n",
        "def extract_link(div): \n",
        "  for a in div.find_all(name='a', attrs={'data-tn-element':'jobTitle'}):\n",
        "    return (a['href'])\n",
        "  return('NOT_FOUND')\n",
        "\n",
        "\n",
        "# extract date of job when it was posted\n",
        "def extract_date(div):\n",
        "  try:\n",
        "    spans = div.findAll('span', attrs={'class': 'date'})\n",
        "    for span in spans:\n",
        "      return (span.text.strip())\n",
        "  except:\n",
        "    return 'NOT_FOUND'\n",
        "  return 'NOT_FOUND'\n",
        "\n",
        "\n",
        "# extract full job description from link\n",
        "def extract_fulltext(url):\n",
        "  try:\n",
        "    page = rq.get('http://www.indeed.com' + url)\n",
        "    soup = bs(page.text, \"lxml\", from_encoding=\"utf-8\")\n",
        "    spans = soup.findAll('span', attrs={'class': 'summary'})\n",
        "    for span in spans:\n",
        "      return (span.text.strip())\n",
        "  except:\n",
        "    return 'NOT_FOUND'\n",
        "  return 'NOT_FOUND'"
      ],
      "metadata": {
        "id": "n948QWKSbq9w"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define dataframe columns\n",
        "df = pd.DataFrame(columns = ['unique_id', 'job_qry','job_title', \n",
        "                             'company_name', 'location', 'summary', \n",
        "                             'salary', 'link', 'date', 'full_text'])"
      ],
      "metadata": {
        "id": "obLrlzPPbrE_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for role in roles:\n",
        "  role_ = role.lower().replace(' ', '+')\n",
        "  link = f'www.indeed.com/jobs?q={role_}&amp;explvl=entry_level'\n",
        "  archive_url_list = get_archive_link(link)\n",
        "  for url in archive_url_list:\n",
        "    for i in range(3): #retry 3 times if connection error\n",
        "      while True:\n",
        "        try:\n",
        "          pg = rq.get(url).text\n",
        "          sleep(3) #ensuring 5 seconds sleep after every grab\n",
        "        except ConnectionError:\n",
        "          sleep(3)\n",
        "          continue\n",
        "        break\n",
        "\n",
        "    soup = bs(pg,'html.parser')\n",
        "    divs = soup.find_all(name=\"div\", attrs={\"class\":\"row\"})\n",
        "\n",
        "    cnt = 0\n",
        "    for div in divs:\n",
        "      #specifying row num for index of job posting in dataframe\n",
        "      num = (len(df) + 1) \n",
        "      cnt = cnt + 1\n",
        "      #job data after parsing\n",
        "      job_post = [] \n",
        "\n",
        "      #append unique id\n",
        "      job_post.append(div['id'])\n",
        "\n",
        "      #append job qry\n",
        "      job_post.append(role)\n",
        "\n",
        "      #grabbing job title\n",
        "      job_post.append(extract_job_title(div))\n",
        "\n",
        "      #grabbing company\n",
        "      job_post.append(extract_company(div))\n",
        "\n",
        "      #grabbing location name\n",
        "      job_post.append(extract_location(div))\n",
        "\n",
        "      #grabbing summary text\n",
        "      job_post.append(extract_summary(div))\n",
        "\n",
        "      #grabbing salary\n",
        "      job_post.append(extract_salary(div))\n",
        "\n",
        "      #grabbing link\n",
        "      link = extract_link(div)\n",
        "      job_post.append(link)\n",
        "\n",
        "      #grabbing date\n",
        "      job_post.append(extract_date(div))\n",
        "\n",
        "      #grabbing full_text\n",
        "      job_post.append(extract_fulltext(link))\n",
        "\n",
        "      #appending list of job post info to dataframe at index num\n",
        "      df.loc[num] = job_post\n",
        "  roles.remove(role)\n",
        "  print(roles)\n",
        "\n",
        "  sleep(5)\n",
        "\n",
        "df.to_csv('job_data_indeed.csv', index=False)"
      ],
      "metadata": {
        "id": "n9UMfooJZzOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# todo \n",
        "# check availability of all the websites and their links \n",
        "# get salary estimates for the years "
      ],
      "metadata": {
        "id": "6cV2bP2jH3G_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "zgmz0lDCga9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 948
        },
        "id": "TENOrxe3efTO",
        "outputId": "3d34d6cd-6788-4f45-eab1-0c3a433d15de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               unique_id               job_qry  \\\n",
              "682   p_f06e91bfa997ad1f        Data Architect   \n",
              "907  pj_47c11da7428e0b9f          Data Analyst   \n",
              "71   pj_cec48dfd230b35f0  Social media manager   \n",
              "952  pj_dd9ac3669ecaa314          Data Analyst   \n",
              "148  pj_311e2f802189c34c   Front end developer   \n",
              "107   p_58ae0d22ebaabfcf   Front end developer   \n",
              "687   p_6d0ab5dd347455d5        Data Architect   \n",
              "497   p_b39789d5af33a063    Software Developer   \n",
              "734   p_d9038819923f6e99          Data Analyst   \n",
              "991   p_7c071c09ee23b304          Data Analyst   \n",
              "\n",
              "                                       job_title                 company_name  \\\n",
              "682                     Data Warehouse Architect                  AffluentTEK   \n",
              "907                          Junior Data Analyst           Abbyson Living LLC   \n",
              "71                          Social Media Manager                   Luv N Care   \n",
              "952               Clinical Trials Data Analyst I  Baylor Scott & White Health   \n",
              "148                         JavaScript Developer                 Indeed Prime   \n",
              "107  UI Developer - W2 (H1 Transfer, GC and USC)      AAA Global Technologies   \n",
              "687                               Data Architect                Core Software   \n",
              "497         Junior Software Development Engineer           Arxan Technologies   \n",
              "734                         Data Quality Analyst                   NerdWallet   \n",
              "991                          Junior Data Analyst                    Good Eggs   \n",
              "\n",
              "                                              location  \\\n",
              "682                                       Richmond, VA   \n",
              "907                                 Moorpark, CA 93021   \n",
              "71                                           NOT_FOUND   \n",
              "952                                         Temple, TX   \n",
              "148                                       Portland, OR   \n",
              "107                                        Atlanta, GA   \n",
              "687                                       Brooklyn, NY   \n",
              "497  San Francisco, CA 94108 (Financial District area)   \n",
              "734                                  San Francisco, CA   \n",
              "991                                  San Francisco, CA   \n",
              "\n",
              "                                               summary  \\\n",
              "682                                          NOT_FOUND   \n",
              "907  Junior Data Analyst. Data analysts work with l...   \n",
              "71                                           NOT_FOUND   \n",
              "952  Works in-tandem with Clinical Trails Data Anal...   \n",
              "148  Apply to 100+ top companies with 1 simple appl...   \n",
              "107  UI Developer - W2 (H1 Transfer, GC and USC). T...   \n",
              "687                                          NOT_FOUND   \n",
              "497  Deliver quality software within the committed ...   \n",
              "734  NerdWallet is seeking a Data Quality Analyst t...   \n",
              "991  Support data gathering and provide review and ...   \n",
              "\n",
              "                             salary  \\\n",
              "682                   [AffluentTEK]   \n",
              "907                       NOT_FOUND   \n",
              "71                     [Luv N Care]   \n",
              "952                       NOT_FOUND   \n",
              "148                       NOT_FOUND   \n",
              "107                       NOT_FOUND   \n",
              "687  [Core Software\\n\\n\\n2 reviews]   \n",
              "497                       NOT_FOUND   \n",
              "734                       NOT_FOUND   \n",
              "991                       NOT_FOUND   \n",
              "\n",
              "                                                  link          date  \\\n",
              "682  /web/20190708124257/https://www.indeed.com/rc/...    1 hour ago   \n",
              "907  /web/20171123153424/https://www.indeed.com/pag...     NOT_FOUND   \n",
              "71   /web/20190805185449/https://www.indeed.com/pag...    1 hour ago   \n",
              "952  /web/20171228171517/https://www.indeed.com/pag...     NOT_FOUND   \n",
              "148  /web/20170901193501/https://www.indeed.com/pag...     NOT_FOUND   \n",
              "107  /web/20170811223815/https://www.indeed.com/com...     1 day ago   \n",
              "687  /web/20190708124257/https://www.indeed.com/rc/...  30+ days ago   \n",
              "497  /web/20171123163650/https://www.indeed.com/rc/...   23 days ago   \n",
              "734  /web/20170811210024/https://www.indeed.com/rc/...    3 days ago   \n",
              "991  /web/20180118164443/https://www.indeed.com/rc/...   30 days ago   \n",
              "\n",
              "     full_text  \n",
              "682  NOT_FOUND  \n",
              "907  NOT_FOUND  \n",
              "71   NOT_FOUND  \n",
              "952  NOT_FOUND  \n",
              "148  NOT_FOUND  \n",
              "107  NOT_FOUND  \n",
              "687  NOT_FOUND  \n",
              "497  NOT_FOUND  \n",
              "734  NOT_FOUND  \n",
              "991  NOT_FOUND  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4ba8e3b1-fbf6-4cf5-95ca-c74f30201de1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_id</th>\n",
              "      <th>job_qry</th>\n",
              "      <th>job_title</th>\n",
              "      <th>company_name</th>\n",
              "      <th>location</th>\n",
              "      <th>summary</th>\n",
              "      <th>salary</th>\n",
              "      <th>link</th>\n",
              "      <th>date</th>\n",
              "      <th>full_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>682</th>\n",
              "      <td>p_f06e91bfa997ad1f</td>\n",
              "      <td>Data Architect</td>\n",
              "      <td>Data Warehouse Architect</td>\n",
              "      <td>AffluentTEK</td>\n",
              "      <td>Richmond, VA</td>\n",
              "      <td>NOT_FOUND</td>\n",
              "      <td>[AffluentTEK]</td>\n",
              "      <td>/web/20190708124257/https://www.indeed.com/rc/...</td>\n",
              "      <td>1 hour ago</td>\n",
              "      <td>NOT_FOUND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>907</th>\n",
              "      <td>pj_47c11da7428e0b9f</td>\n",
              "      <td>Data Analyst</td>\n",
              "      <td>Junior Data Analyst</td>\n",
              "      <td>Abbyson Living LLC</td>\n",
              "      <td>Moorpark, CA 93021</td>\n",
              "      <td>Junior Data Analyst. Data analysts work with l...</td>\n",
              "      <td>NOT_FOUND</td>\n",
              "      <td>/web/20171123153424/https://www.indeed.com/pag...</td>\n",
              "      <td>NOT_FOUND</td>\n",
              "      <td>NOT_FOUND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>pj_cec48dfd230b35f0</td>\n",
              "      <td>Social media manager</td>\n",
              "      <td>Social Media Manager</td>\n",
              "      <td>Luv N Care</td>\n",
              "      <td>NOT_FOUND</td>\n",
              "      <td>NOT_FOUND</td>\n",
              "      <td>[Luv N Care]</td>\n",
              "      <td>/web/20190805185449/https://www.indeed.com/pag...</td>\n",
              "      <td>1 hour ago</td>\n",
              "      <td>NOT_FOUND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>952</th>\n",
              "      <td>pj_dd9ac3669ecaa314</td>\n",
              "      <td>Data Analyst</td>\n",
              "      <td>Clinical Trials Data Analyst I</td>\n",
              "      <td>Baylor Scott &amp; White Health</td>\n",
              "      <td>Temple, TX</td>\n",
              "      <td>Works in-tandem with Clinical Trails Data Anal...</td>\n",
              "      <td>NOT_FOUND</td>\n",
              "      <td>/web/20171228171517/https://www.indeed.com/pag...</td>\n",
              "      <td>NOT_FOUND</td>\n",
              "      <td>NOT_FOUND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>pj_311e2f802189c34c</td>\n",
              "      <td>Front end developer</td>\n",
              "      <td>JavaScript Developer</td>\n",
              "      <td>Indeed Prime</td>\n",
              "      <td>Portland, OR</td>\n",
              "      <td>Apply to 100+ top companies with 1 simple appl...</td>\n",
              "      <td>NOT_FOUND</td>\n",
              "      <td>/web/20170901193501/https://www.indeed.com/pag...</td>\n",
              "      <td>NOT_FOUND</td>\n",
              "      <td>NOT_FOUND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>p_58ae0d22ebaabfcf</td>\n",
              "      <td>Front end developer</td>\n",
              "      <td>UI Developer - W2 (H1 Transfer, GC and USC)</td>\n",
              "      <td>AAA Global Technologies</td>\n",
              "      <td>Atlanta, GA</td>\n",
              "      <td>UI Developer - W2 (H1 Transfer, GC and USC). T...</td>\n",
              "      <td>NOT_FOUND</td>\n",
              "      <td>/web/20170811223815/https://www.indeed.com/com...</td>\n",
              "      <td>1 day ago</td>\n",
              "      <td>NOT_FOUND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>687</th>\n",
              "      <td>p_6d0ab5dd347455d5</td>\n",
              "      <td>Data Architect</td>\n",
              "      <td>Data Architect</td>\n",
              "      <td>Core Software</td>\n",
              "      <td>Brooklyn, NY</td>\n",
              "      <td>NOT_FOUND</td>\n",
              "      <td>[Core Software\\n\\n\\n2 reviews]</td>\n",
              "      <td>/web/20190708124257/https://www.indeed.com/rc/...</td>\n",
              "      <td>30+ days ago</td>\n",
              "      <td>NOT_FOUND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>p_b39789d5af33a063</td>\n",
              "      <td>Software Developer</td>\n",
              "      <td>Junior Software Development Engineer</td>\n",
              "      <td>Arxan Technologies</td>\n",
              "      <td>San Francisco, CA 94108 (Financial District area)</td>\n",
              "      <td>Deliver quality software within the committed ...</td>\n",
              "      <td>NOT_FOUND</td>\n",
              "      <td>/web/20171123163650/https://www.indeed.com/rc/...</td>\n",
              "      <td>23 days ago</td>\n",
              "      <td>NOT_FOUND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>734</th>\n",
              "      <td>p_d9038819923f6e99</td>\n",
              "      <td>Data Analyst</td>\n",
              "      <td>Data Quality Analyst</td>\n",
              "      <td>NerdWallet</td>\n",
              "      <td>San Francisco, CA</td>\n",
              "      <td>NerdWallet is seeking a Data Quality Analyst t...</td>\n",
              "      <td>NOT_FOUND</td>\n",
              "      <td>/web/20170811210024/https://www.indeed.com/rc/...</td>\n",
              "      <td>3 days ago</td>\n",
              "      <td>NOT_FOUND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>991</th>\n",
              "      <td>p_7c071c09ee23b304</td>\n",
              "      <td>Data Analyst</td>\n",
              "      <td>Junior Data Analyst</td>\n",
              "      <td>Good Eggs</td>\n",
              "      <td>San Francisco, CA</td>\n",
              "      <td>Support data gathering and provide review and ...</td>\n",
              "      <td>NOT_FOUND</td>\n",
              "      <td>/web/20180118164443/https://www.indeed.com/rc/...</td>\n",
              "      <td>30 days ago</td>\n",
              "      <td>NOT_FOUND</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ba8e3b1-fbf6-4cf5-95ca-c74f30201de1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4ba8e3b1-fbf6-4cf5-95ca-c74f30201de1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4ba8e3b1-fbf6-4cf5-95ca-c74f30201de1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n6bG-n_O47sJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}